# -*- coding: utf-8 -*-
"""CICIoT23_EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZHJUcsNDxs_e7SdkJaHkb3A5tvVOVaQT
"""

import pandas as pd
import numpy as np
import os
from tqdm import tqdm
import seaborn as sns

from google.colab import userdata
import os

os.environ["KAGGLE_KEY"] = userdata.get('KAGGLE_KEY')
os.environ["KAGGLE_USERNAME"] = userdata.get('KAGGLE_USERNAME')

!kaggle datasets download -d akashdogra/cic-iot-2023

!pip install opendatasets

import zipfile

# Unzip the downloaded file
zip_ref = zipfile.ZipFile("/content/cic-iot-2023.zip", "r")
zip_ref.extractall()
zip_ref.close()

count=0
directory_list=[]
for dirname, _, filenames in os.walk('/content'):
    for filename in tqdm(filenames):
        filen = os.path.join(dirname, filename)
        if filen.endswith(".csv"):
          directory_list.append(os.path.join(dirname, filename))
          print(os.path.join(dirname, filename))
          count=count+1

print(count)

df = pd.read_csv('/content/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')
data_dir = '/content/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv'
df.head()

len(df['label'].unique())

df['label'].unique()

df['label'].value_counts()

df.info()

df.describe()

len(df)



#!pip install torch

!python -m torch.utils.collect_env

#!pip install torch torchvision torchaudio

#!pip install --upgrade torch torchvision torchaudio

import matplotlib.pyplot as plt
plt.figure(figsize=(10,7))
plt.hist(df['label'],bins=30)
plt.xticks(rotation=60,ha='right')
plt.xlabel('Attack_Types')
plt.ylabel('Frequency')
plt.show()

benign_data = df[df.label=='BenignTraffic']
benign_data

benign_data.describe()

#Correlation matrix
import seaborn as sns
plt.figure(figsize=(50,25))
X = df.corr()
sns.heatmap(X,annot=True)
plt.show()



df.head()

# Creating a dictionary of attack types for 33 attack classes + 1 for benign traffic
dict_34_classes = {'BenignTraffic': 0 ,
                    'DDoS-RSTFINFlood' :1, 'DDoS-PSHACK_Flood':2,  'DDoS-SYN_Flood':3, 'DDoS-UDP_Flood':4, 'DDoS-TCP_Flood':5,
                    'DDoS-ICMP_Flood':6, 'DDoS-SynonymousIP_Flood':7, 'DDoS-ACK_Fragmentation':8, 'DDoS-UDP_Fragmentation':9, 'DDoS-ICMP_Fragmentation':10,
                    'DDoS-SlowLoris':11, 'DDoS-HTTP_Flood':12, 'DoS-UDP_Flood':13, 'DoS-SYN_Flood':14, 'DoS-TCP_Flood':15, 'DoS-HTTP_Flood':16,                 # DDoS and DoS
                    'Mirai-greeth_flood': 17, 'Mirai-greip_flood': 18, 'Mirai-udpplain': 19,                                                                    # Mirai
                    'Recon-PingSweep': 20, 'Recon-OSScan': 21, 'Recon-PortScan': 22, 'VulnerabilityScan': 23, 'Recon-HostDiscovery': 24,                        # Reconnaissance
                    'DNS_Spoofing': 25, 'MITM-ArpSpoofing': 26,                                                                                                 # Spoofing
                    'BrowserHijacking': 27, 'Backdoor_Malware': 28, 'XSS': 29, 'Uploading_Attack': 30, 'SqlInjection': 31, 'CommandInjection': 32,              # Web
                    'DictionaryBruteForce': 33}                                                                                                                 # Brute Force

dict_7_classes = {  0: 0 ,
                    1 :1, 2:1,  3:1, 4:1, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 11:1, 12:1, 13:1, 14:1, 15:1, 16:1,                                                    # DDoS and DoS
                    17: 2, 18: 2, 19: 2,                                                                                                                        # Mirai
                    20: 3, 21: 3, 22: 3, 23: 3, 24: 3,                                                                                                          # Reconnaissance
                    25: 4, 26: 4,                                                                                                                               # Spoofing
                    27: 5, 28: 5, 29: 5, 30: 5, 31: 5, 32: 5,                                                                                                   # Web
                    33: 6}                                                                                                                                      # Brute Force

dict_2_classes = {  0: 0 ,
                    1 :1, 2:1,  3:1, 4:1, 5:1, 6:1, 7:1, 8:1, 9:1, 10:1, 11:1, 12:1, 13:1, 14:1, 15:1, 16:1,                                                    # DDoS and DoS
                    17: 1, 18: 1, 19: 1,                                                                                                                        # Mirai
                    20: 1, 21: 1, 22: 1, 23: 1, 24: 1,                                                                                                          # Reconnaissance
                    25: 1, 26: 1,                                                                                                                               # Spoofing
                    27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1,                                                                                                   # Web
                    33: 1}                                                                                                                                      # Brute Force



#Drop features with 0 standard dev
columns_to_drop = ['Drate',	'fin_flag_number',	'syn_flag_number',	'rst_flag_number','Telnet',	'SMTP',	'SSH','IRC','DHCP','ICMP']
benign_data.drop(columns=columns_to_drop,inplace=True)
benign_data.head()

selected_rows = df[df['label'].str.startswith('Recon')]

selected_rows

# Importing Scikit learn package to do scaling/pricipal componend analysis
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import random

# Plotting the data in scatter plot to view how distributed the data
def plot_2d_scatter_plot(df, title):
    X = df.drop(['label'], axis=1).values
    y = df['label'].values
    X_std = StandardScaler().fit_transform(X)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_std)
    data_X = X_pca[:,0]
    data_Y = X_pca[:,1]
    data_Z = y
    print(data_X,data_Y,data_Z)

    # colors = ["#ff0000", "#006600", "#ffff00"]
    # # Set your custom color palette
    colors = ['#' + ''.join(random.choices('0123456789abcdef', k=6)) for _ in range(34)]

    customPalette = sns.set_palette(sns.color_palette(colors))

    sns.set(rc={'figure.figsize':(12,9)})
    sns.scatterplot(x=data_X, y=data_Y, hue=data_Z,palette=customPalette).set_title(title)
    # plt.xlim(0,20)
    # plt.ylim(0,15)

from scipy.stats import norm
X = df.drop(['label'], axis=1).values
y = df['label'].values
X_std = StandardScaler().fit_transform(X)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_std)
data_X = X_pca[:,0]
data_Y = X_pca[:,1]
data_Z = y
# Create normal distributions
mean_x1 = np.mean(data_X)
std_dev_x1 = np.std(data_X)

mean_x2 = np.mean(data_Y)
std_dev_x2 = np.std(data_Y)

pdf_x1 = norm.pdf(data_X, mean_x1, std_dev_x1)
pdf_x2 = norm.pdf(data_Y,mean_x2 , std_dev_x2)

# Plot normal curves
plt.scatter(data_X, data_Y , label='x1', color='blue')
plt.xlabel('x1')
plt.ylabel('x2')
# plt.plot(data_Y, pdf_x2, label='x2', color='red')

plot_2d_scatter_plot(benign_data, 'Benign')

plot_2d_scatter_plot(df, 'Full_data')

"""## 3-D Scatter Plot"""

# Importing visualization package
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

plt.rcParams["figure.figsize"] = (12,9)

# Function to visualize Scatter in 3D
def plot_3d_scatter_plot(df, title):
    X = df.drop(['label'], axis=1).values
    df["label"] = df["label"].replace(dict_34_classes)
    df["label"] = df["label"].replace(dict_7_classes)
    y = df['label'].values
    X_std = StandardScaler().fit_transform(X)
    pca = PCA(n_components=3)  # Update to 3 components for 3D scatter plot
    X_pca = pca.fit_transform(X_std)

    data_X = X_pca[:, 0]
    data_Y = X_pca[:, 1]
    data_Z = X_pca[:, 2]  # Add third dimension for 3D scatter plot

    data = np.column_stack((data_X, data_Y, data_Z, y))

    # Define colors and labels for legend
    colors = ['green', 'red', 'orange', 'blue', 'purple', 'yellow', 'cyan']
    labels = ['Benign','DDoS','Mirai','Reconnaissance','Spoofing','Web','Brute-Force']

    # Create legend handles
    handles = [mpatches.Patch(color=colors[i], label=labels[i]) for i in range(len(labels))]

    X = data[:, 0]
    Y = data[:, 1]
    Z = data[:, 2]
    labels = data[:, 3]

    ax = plt.axes(projection='3d')
    C = [colors[int(label)] for label in labels]  # Assign colors based on labels
    ax.scatter(X, Y, Z, c=C)

    ax.set_title(title)
    ax.legend(handles=handles)

    plt.show()

# Example usage:
plot_3d_scatter_plot(df, '3D Scatter Plot with PCA')

# Function to visualize Scatter in 3D
def plot_3d_scatter_plot(df, title):
    X = df.drop(['label'], axis=1).values
    df["label"] = df["label"].replace(dict_34_classes)
    df["label"] = df["label"].replace(dict_7_classes)
    y = df['label'].values
    X_std = StandardScaler().fit_transform(X)
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_std)
    print(X_pca,X_pca.dtype)


    data_X = X_pca[:,0]
    data_Y = X_pca[:,1]
    data_Z = y

    data = np.column_stack((data_X, data_Y, data_Z))

    benign = mpatches.Patch(color='green', label='Benign')
    dos = mpatches.Patch(color='red', label='dos')
    mirai = mpatches.Patch(color='orange', label='Mirai')
    reconnaisance =  mpatches.Patch(color='blue', label='recon')
    spoofing =  mpatches.Patch(color='yellow', label='spoofing')
    web =  mpatches.Patch(color='violet', label='web')
    brute_force =  mpatches.Patch(color='pink', label='brute_force')
    handles = [benign, dos, mirai,reconnaisance,spoofing,web,brute_force]

    X = data[:,0]
    Y = data[:,1]
    Z = data[:,2]


    # for z in Z:
    #   print(z)

    ax = plt.axes(projection='3d')
    C = ['green' if z == 0 else 'red' if z == 1 else 'orange' for z in Z]
    ax.scatter(X, Y, Z, c = C, cmap='RdYlGn')
    ax.set_title(title);
    plt.legend(handles=handles)
    plt.show()



# Visualizing
plot_3d_scatter_plot(benign_data, 'benign_data')

plot_3d_scatter_plot(df,'Full_data')

df['label'] = df['label'].map(dict_34_classes)
df.head()

# !pip install autoviz
# from autoviz.AutoViz_Class import AutoViz_Class
# AV = AutoViz_Class()
# sep = ','
# dft = AV.AutoViz(data_dir, sep, header=0, verbose=0, lowess=False, chart_format='svg', max_rows_analyzed=150000, max_cols_analyzed=30)





# import torch
# from torch.utils.data import DataLoader, Dataset
# import pandas as pd

# class CSVDataset(Dataset):
#     def __init__(self, csv_file):
#         self.data = pd.read_csv(csv_file)

#     def __len__(self):
#         return len(self.data)

#     def __getitem__(self, idx):
#         return self.data.iloc[idx]

# class ConcatDataset(Dataset):
#     def __init__(self, datasets):
#         self.datasets = datasets

#     def __len__(self):
#         return sum(len(dataset) for dataset in self.datasets)

#     def __getitem__(self, idx):
#         dataset_idx, idx_in_dataset = 0, idx
#         while idx_in_dataset >= len(self.datasets[dataset_idx]):
#             idx_in_dataset -= len(self.datasets[dataset_idx])
#             dataset_idx += 1
#         return self.datasets[dataset_idx][idx_in_dataset]

# # Create a list of CSV file names
# csv_files = directory_list

# # Create a list of CSVDatasets
# datasets = [CSVDataset(csv_file) for csv_file in csv_files]

# # Create a ConcatDataset
# concat_dataset = ConcatDataset(datasets)

# len(concat_dataset)
# # Create a DataLoader
# dataloader = DataLoader(concat_dataset, batch_size=32, shuffle=True)

# # Iterate over the dataloader
# for batch in dataloader:
#     # Do something with the batch
#     pass

# count=0
# for dirname, _, filenames in os.walk('/content'):
#     for filename in tqdm(filenames):
#         filen = os.path.join(dirname, filename)
#         if (filen.endswith(".csv")):
#           filen = pd.read_csv(os.path.join(dirname, filename))
#           df =  pd.concat([df,filen])
#           count=count+1
#           print(count)

# print(count)